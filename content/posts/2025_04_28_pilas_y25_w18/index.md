---
author: "Jorge Roldan"
date: '2025-04-28'
title: 'üîã Pilas: y25-w18'
categories: ['newsletter']
ShowToc: true
ShowBreadCrumbs: false
---

# Models/Systems
## Qwen3 - 04/29/25  
- Released by: 
- [Model - Alibaba unveils Qwen3, a family of ‚Äòhybrid‚Äô AI reasoning models](https://techcrunch.com/2025/04/28/alibaba-unveils-qwen-3-a-family-of-hybrid-ai-reasoning-models/)
 ‚≠êÔ∏è
-  https://qwenlm.github.io/blog/qwen3/

{{< x user="Alibaba_Qwen" id="1916962087676612998" >}}


## Byte Latent Transformer (blt) - Meta - 04/30/25
- **Hugging Face model card**:  [facebook/blt](https://huggingface.co/facebook/blt)
- **Paper**: [Byte Latent Transformer: Patches Scale Better Than Tokens](https://dl.fbaipublicfiles.com/blt/BLT__Patches_Scale_Better_Than_Tokens.pdf)
- **code**: [facebookresearch/blt](https://github.com/facebookresearch/blt)


## Phi-4 - Microsoft - 04/30/25
- **Announcement**: [One year of Phi: Small language models making big leaps in AI](https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/)
- **Article**: [Microsoft‚Äôs most capable new Phi 4 AI model rivals the performance of far larger systems](https://techcrunch.com/2025/04/30/microsofts-most-capable-new-phi-4-ai-model-rivals-the-performance-of-far-larger-systems/)
- **Paper**: [Phi-4-reasoning Technical Report](https://arxiv.org/abs/2504.21318)

## Mellum - JetBrains - 04/30/25
- **Announcement**: [Mellum Goes Open Source: A Purpose-Built LLM for Developers, Now on Hugging Face](https://blog.jetbrains.com/ai/2025/04/mellum-goes-open-source-a-purpose-built-llm-for-developers-now-on-hugging-face/)
- **Hugging Face model card**: [JetBrains/Mellum-4b-base](https://huggingface.co/JetBrains/Mellum-4b-base)


## OLMo 2 - AllenAI - 05/01/25
- **Project page**: [OLMo 2](https://allenai.org/olmo)
- **Hugging Face Collection**: [OLMo 2](https://huggingface.co/collections/allenai/olmo-2-674117b93ab84e98afc72edc)
- **Paper**: [2 OLMo 2 Furious](https://arxiv.org/abs/2501.00656)


## Llama-Nemotron: Efficient Reasoning Models - 05/02/25
- [Paper](https://arxiv.org/abs/2505.00949)
- [NVIDIA Llama Nemotron Ultra Open Model Delivers Groundbreaking Reasoning Accuracy](https://developer.nvidia.com/blog/nvidia-llama-nemotron-ultra-open-model-delivers-groundbreaking-reasoning-accuracy/)
- [Hugging Face space](https://huggingface.co/collections/nvidia/llama-nemotron-67d92346030a2691293f200b)


## F Lite - 04/29/25
- [F Lite - freepik - 04/29/25](https://github.com/fal-ai/f-lite/blob/main/README.md)


# Agents
- [AMIE gains vision: A research AI agent for multimodal diagnostic dialogue](https://research.google/blog/amie-gains-vision-a-research-ai-agent-for-multi-modal-diagnostic-dialogue/)

# Papers
- [OLMOTRACE: Tracing Language Model Outputs Back to Trillions of Training Tokens](https://arxiv.org/pdf/2504.07096)
- [The Leaderboard Illusion](https://arxiv.org/abs/2504.20879) - 04/29/2
- [Phi-4-reasoning Technical Report](https://arxiv.org/abs/2504.21318) - 04/30/25
- [Byte Latent Transformer: Patches Scale Better Than Tokens](https://dl.fbaipublicfiles.com/blt/BLT__Patches_Scale_Better_Than_Tokens.pdf)
- [All Roads Lead to Likelihood: The Value of Reinforcement Learning in Fine-Tuning](https://arxiv.org/abs/2503.01067) - 05/03/25
- [WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org/abs/2504.21776)
- [Talk Before You Retrieve: Agent-Led Discussions for Better RAG in
Medical QA](https://arxiv.org/pdf/2504.21252)
- [Practical Efficiency of Muon for Pretraining](https://arxiv.org/abs/2505.02222) - 05/04/25

# Articles
- [Why We Think](https://lilianweng.github.io/posts/2025-05-01-thinking/) by Lilian Weng

# Lectures
- [Yann LeCun: Models of SSL](https://www.youtube.com/watch?v=AfqWt1rk7TE) - 04/29/25

{{< youtube AfqWt1rk7TE >}}